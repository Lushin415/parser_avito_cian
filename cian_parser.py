import asyncio
import json
import random
import time
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse
from cian_cities import get_city_code, is_city_supported, get_all_cities, get_cities_count

from bs4 import BeautifulSoup
from curl_cffi import requests
from loguru import logger
from requests.cookies import RequestsCookieJar

from cian_models import CianItem
from common_data import HEADERS
from db_service import SQLiteDBHandler
from dto import Proxy, CianConfig
from get_cookies import get_cookies
from hide_private_data import log_config
from tg_sender import SendAdToTg
from vk_sender import SendAdToVK
from version import VERSION
from xlsx_service import XLSXHandler


class CianParser:
    def __init__(self, config: CianConfig, stop_event=None):
        self.config = config
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≥–æ—Ä–æ–¥–∞
        if not is_city_supported(self.config.location):
            available_cities = ", ".join(get_all_cities()[:10])
            raise ValueError(
                f"–ì–æ—Ä–æ–¥ '{self.config.location}' –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –¶–∏–∞–Ω.\n"
                f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –≥–æ—Ä–æ–¥–∞: {available_cities}... (–≤—Å–µ–≥–æ {get_cities_count()} –≥–æ—Ä–æ–¥–æ–≤)"
            )

        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–¥ –≥–æ—Ä–æ–¥–∞
        self.city_code = get_city_code(self.config.location)
        logger.info(f"üìç –ì–æ—Ä–æ–¥: {self.config.location} (–∫–æ–¥ —Ä–µ–≥–∏–æ–Ω–∞: {self.city_code})")
        self.proxy_obj = self.get_proxy_obj()
        self.db_handler = SQLiteDBHandler()
        self.tg_handler = self.get_tg_handler()
        self.vk_handler = self.get_vk_handler()
        self.xlsx_handler = XLSXHandler(self.__get_file_title())
        self.stop_event = stop_event
        self.cookies = None
        self.session = requests.Session()
        self.headers = HEADERS.copy()
        self.good_request_count = 0
        self.bad_request_count = 0

        log_config(config=self.config, version=VERSION)
        logger.info(f"–ó–∞–ø—É—Å–∫ CianParser v{VERSION}")
        logger.info(f"–ù–∞—Å—Ç—Ä–æ–π–∫–∏: location={config.location}, deal_type={config.deal_type}")
        logger.info(f"–§–∏–ª—å—Ç—Ä—ã: —Ü–µ–Ω–∞ {config.min_price}-{config.max_price}, –ø–ª–æ—â–∞–¥—å {config.min_area}-{config.max_area}")

    def get_tg_handler(self) -> SendAdToTg | None:
        if all([self.config.tg_token, self.config.tg_chat_id]):
            return SendAdToTg(bot_token=self.config.tg_token, chat_id=self.config.tg_chat_id)
        return None

    def get_vk_handler(self) -> SendAdToVK | None:
        if all([self.config.vk_token, self.config.vk_user_id]):
            logger.info("VK handler –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return SendAdToVK(vk_token=self.config.vk_token, user_id=self.config.vk_user_id)
        return None

    def _send_to_tg(self, ads: list[CianItem]) -> None:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è –≤ Telegram"""
        for ad in ads:
            self.tg_handler.send_to_tg(ad=ad)

    def _send_to_vk(self, ads: list[CianItem]) -> None:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è –≤ VK"""
        for ad in ads:
            self.vk_handler.send_to_vk(ad=ad)
            time.sleep(1)

    def get_proxy_obj(self) -> Proxy | None:
        if all([self.config.proxy_string, self.config.proxy_change_url]):
            return Proxy(
                proxy_string=self.config.proxy_string,
                change_ip_link=self.config.proxy_change_url
            )
        logger.info("–†–∞–±–æ—Ç–∞–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏")
        return None

    def get_cookies(self, max_retries: int = 1, delay: float = 2.0) -> dict | None:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ cookies —á–µ—Ä–µ–∑ Playwright (–æ–±—Ö–æ–¥ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫)"""
        if not self.config.use_webdriver:
            return None

        for attempt in range(1, max_retries + 1):
            if self.stop_event and self.stop_event.is_set():
                return None

            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–π ID –æ–±—ä—è–≤–ª–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è cookies
                random_id = str(random.randint(100000000, 999999999))
                test_url = f"https://www.cian.ru/rent/flat/{random_id}/"

                cookies, user_agent = asyncio.run(
                    get_cookies(proxy=self.proxy_obj, headless=True, stop_event=self.stop_event))

                if cookies:
                    logger.info(f"[get_cookies] –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã cookies —Å –ø–æ–ø—ã—Ç–∫–∏ {attempt}")
                    self.headers["user-agent"] = user_agent
                    return cookies
                else:
                    raise ValueError("–ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç cookies")
            except Exception as e:
                logger.warning(f"[get_cookies] –ü–æ–ø—ã—Ç–∫–∞ {attempt} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
                if attempt < max_retries:
                    time.sleep(delay * attempt)
                else:
                    logger.error(f"[get_cookies] –í—Å–µ {max_retries} –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å")
                    return None

    def save_cookies(self) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç cookies –≤ JSON —Ñ–∞–π–ª"""
        with open("cookies_cian.json", "w") as f:
            json.dump(self.session.cookies.get_dict(), f)

    def load_cookies(self) -> None:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç cookies –∏–∑ JSON —Ñ–∞–π–ª–∞"""
        try:
            with open("cookies_cian.json", "r") as f:
                cookies = json.load(f)
                jar = RequestsCookieJar()
                for k, v in cookies.items():
                    jar.set(k, v)
                self.session.cookies.update(jar)
        except FileNotFoundError:
            pass

    def fetch_data(self, url, retries=3, backoff_factor=1):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –æ–±—Ö–æ–¥–æ–º –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫"""
        proxy_data = None
        if self.proxy_obj:
            proxy_data = {
                "https": f"http://{self.config.proxy_string}"
            }

        for attempt in range(1, retries + 1):
            if self.stop_event and self.stop_event.is_set():
                return None

            try:
                response = self.session.get(
                    url=url,
                    headers=self.headers,
                    proxies=proxy_data,
                    cookies=self.cookies,
                    impersonate="chrome",
                    timeout=20,
                    verify=False,
                )
                logger.debug(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt}: {response.status_code}")

                if response.status_code >= 500:
                    raise requests.RequestsError(f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {response.status_code}")

                if response.status_code in [302, 403, 429]:
                    self.bad_request_count += 1
                    self.session = requests.Session()
                    if attempt >= 3:
                        self.cookies = self.get_cookies()
                    self.change_ip()
                    raise requests.RequestsError(f"–ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞: {response.status_code}")

                self.save_cookies()
                self.good_request_count += 1
                return response.text

            except Exception as e:
                logger.debug(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt} –Ω–µ—É—Å–ø–µ—à–Ω–∞: {e}")
                if attempt < retries:
                    sleep_time = backoff_factor * attempt
                    logger.debug(f"–ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {sleep_time} —Å–µ–∫—É–Ω–¥...")
                    time.sleep(sleep_time)
                else:
                    logger.info("–í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ—É—Å–ø–µ—à–Ω—ã")
                    return None

    def change_ip(self) -> bool:
        """–°–º–µ–Ω–∞ IP —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏"""
        if not self.config.proxy_change_url:
            logger.info("–°–º–µ–Ω–∞ IP –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (–Ω–µ—Ç –ø—Ä–æ–∫—Å–∏)")
            return False

        logger.info("–ú–µ–Ω—è—é IP")
        try:
            res = requests.get(url=self.config.proxy_change_url, verify=False)
            if res.status_code == 200:
                logger.info("IP –∏–∑–º–µ–Ω–µ–Ω")
                return True
        except Exception as err:
            logger.info(f"–û—à–∏–±–∫–∞ —Å–º–µ–Ω—ã IP: {err}")

        logger.info("–ü–æ–≤—Ç–æ—Ä —Å–º–µ–Ω—ã IP")
        time.sleep(random.randint(3, 10))
        return self.change_ip()

    def parse_list_page(self, html: str) -> list[CianItem]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å–ø–∏—Å–∫–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        soup = BeautifulSoup(html, 'html.parser')

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–∞–ø—á—É
        if "Captcha" in html or "captcha" in html.lower():
            logger.warning("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–∞–ø—á–∞!")
            return []

        # –ò—â–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏—è (–¥–ª—è –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–π –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥—Ä—É–≥–æ–π —Å–µ–ª–µ–∫—Ç–æ—Ä)
        offers = soup.select("div[data-name='HorizontalCard']")

        if not offers:
            logger.warning("–û–±—ä—è–≤–ª–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
            return []

        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(offers)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")

        ads = []
        for offer in offers:
            try:
                ad = self.parse_single_offer(offer)
                if ad:
                    ads.append(ad)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è: {e}")
                continue

        return ads

    def parse_single_offer(self, offer) -> CianItem | None:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–π –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏"""
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ helpers
            from cian_helpers import (
                parse_author,
                parse_location,
                parse_description,
                extract_price_from_title,
                extract_area_from_title
            )

            # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Å—Å—ã–ª–∫—É
            title_link = offer.select_one("a[data-name='CommercialTitle']")
            if not title_link:
                return None

            url = title_link.get('href', '')
            if not url:
                return None

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            title = title_link.get_text(strip=True)

            # ID –∏–∑ URL
            ad_id = self._extract_id_from_url(url)

            # –ü–∞—Ä—Å–∏–º —Ü–µ–Ω—É –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            price_value = extract_price_from_title(title)

            # –ü–∞—Ä—Å–∏–º –ø–ª–æ—â–∞–¥—å –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            total_meters = extract_area_from_title(title)

            # –°–æ–∑–¥–∞—ë–º –æ–±—ä–µ–∫—Ç —Ü–µ–Ω—ã
            from cian_models import CianPrice
            price = CianPrice(
                value=price_value,
                price_per_month=price_value if self.config.deal_type == "rent_long" else None
            )

            # –ü–∞—Ä—Å–∏–º –∞–≤—Ç–æ—Ä–∞
            author = parse_author(offer)

            # –ü–∞—Ä—Å–∏–º –∞–¥—Ä–µ—Å
            location = parse_location(offer)

            # –ü–∞—Ä—Å–∏–º –æ–ø–∏—Å–∞–Ω–∏–µ
            description = parse_description(offer)

            # –°–æ–∑–¥–∞—ë–º –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
            ad = CianItem(
                id=ad_id,
                url=url if url.startswith('http') else f"https://cian.ru{url}",
                title=title,
                location=self.config.location,
                deal_type=self.config.deal_type,
                price=price,
                total_meters=total_meters,
                author=author,
                location_data=location,
                description=description,
            )

            return ad

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è: {e}")
            return None

    def _extract_price_from_title(self, title: str) -> int:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ü–µ–Ω—É –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        import re

        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã: "–∑–∞ 720 000 —Ä—É–±." –∏–ª–∏ "–æ—Ç 674 208 ‚ÇΩ"
        patterns = [
            r'–∑–∞\s+([\d\s]+)\s*(?:—Ä—É–±|‚ÇΩ)',  # "–∑–∞ 720 000 —Ä—É–±."
            r'–æ—Ç\s*([\d\s]+)\s*(?:—Ä—É–±|‚ÇΩ)',  # "–æ—Ç 674 208 ‚ÇΩ"
        ]

        for pattern in patterns:
            match = re.search(pattern, title)
            if match:
                price_str = match.group(1).replace(' ', '').replace('\xa0', '')
                try:
                    return int(price_str)
                except ValueError:
                    continue

        return 0

    def _extract_area_from_title(self, title: str) -> float:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–ª–æ—â–∞–¥—å –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        import re

        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã: "209,7 –º¬≤" –∏–ª–∏ "147,1 ‚Äì 1 433,4 –º¬≤"
        patterns = [
            r'([\d\s,]+)\s*–º[¬≤2]',  # "209,7 –º¬≤"
        ]

        for pattern in patterns:
            match = re.search(pattern, title)
            if match:
                area_str = match.group(1).replace(' ', '').replace(',', '.')
                try:
                    # –ë–µ—Ä—ë–º –ø–µ—Ä–≤–æ–µ —á–∏—Å–ª–æ (–µ—Å–ª–∏ –¥–∏–∞–ø–∞–∑–æ–Ω)
                    first_number = area_str.split('‚Äì')[0].strip()
                    return float(first_number)
                except ValueError:
                    continue

        return -1.0

    def _extract_id_from_url(self, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç ID –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–∑ URL"""
        parts = url.split('/')
        for part in reversed(parts):
            if part.isdigit():
                return part
        return str(abs(hash(url)))[:10]

    def filter_ads(self, ads: list[CianItem]) -> list[CianItem]:
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ–±—ä—è–≤–ª–µ–Ω–∏–π"""
        filters = [
            self._filter_viewed,
            self._filter_by_price_range,
            self._filter_by_area,
        ]

        for filter_fn in filters:
            ads = filter_fn(ads)
            logger.info(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ {filter_fn.__name__}: {len(ads)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
            if not ads:
                return ads

        return ads

    def _filter_viewed(self, ads: list[CianItem]) -> list[CianItem]:
        """–§–∏–ª—å—Ç—Ä –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö"""
        try:
            return [ad for ad in ads if not self.is_viewed(ad)]
        except Exception as err:
            logger.debug(f"–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö: {err}")
            return ads

    def _filter_by_price_range(self, ads: list[CianItem]) -> list[CianItem]:
        """–§–∏–ª—å—Ç—Ä –ø–æ —Ü–µ–Ω–µ"""
        try:
            return [
                ad for ad in ads
                if self.config.min_price <= ad.price.value <= self.config.max_price
            ]
        except Exception as err:
            logger.debug(f"–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ —Ü–µ–Ω–µ: {err}")
            return ads

    def _filter_by_area(self, ads: list[CianItem]) -> list[CianItem]:
        """–§–∏–ª—å—Ç—Ä –ø–æ –ø–ª–æ—â–∞–¥–∏"""
        if self.config.min_area == 0 and self.config.max_area == 999_999:
            return ads

        try:
            return [
                ad for ad in ads
                if ad.total_meters > 0 and
                   self.config.min_area <= ad.total_meters <= self.config.max_area
            ]
        except Exception as err:
            logger.debug(f"–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ –ø–ª–æ—â–∞–¥–∏: {err}")
            return ads

    def is_viewed(self, ad: CianItem) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–æ –ª–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ"""
        # –ï—Å–ª–∏ –Ω–µ—Ç —Ü–µ–Ω—ã, —Å—á–∏—Ç–∞–µ–º –Ω–µ–ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–º
        if not ad.price:
            return False

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º ID –≤ int
        ad_id = int(ad.id) if ad.id.isdigit() else abs(hash(ad.id))

        return self.db_handler.record_exists(
            record_id=ad_id,
            price=ad.price.value
        )

    def __get_file_title(self) -> str:
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è"""
        return f"result/cian_{self.config.location.lower()}.xlsx"

    def __save_data(self, ads: list[CianItem]) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–∞–π–ª"""
        try:
            logger.info(f"üìä –í—ã–∑–≤–∞–Ω __save_data —Å {len(ads)} –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º–∏")  # ‚Üê –î–û–ë–ê–í–¨
            self.xlsx_handler.append_data_from_page(ads=ads)
            logger.info("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Excel –∑–∞–≤–µ—Ä—à–µ–Ω–æ")  # ‚Üê –î–û–ë–ê–í–¨
        except Exception as err:
            logger.error(f"‚ùå –ü—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ Excel –æ—à–∏–±–∫–∞: {err}")
            import traceback
            logger.error(traceback.format_exc())  # ‚Üê –î–û–ë–ê–í–¨ (–ø–æ–ª–Ω—ã–π —Å—Ç–µ–∫ –æ—à–∏–±–∫–∏)

    def __save_viewed(self, ads: list[CianItem]) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π –≤ –ë–î"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º CianItem –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –ë–î
            records = [
                self._convert_cian_to_db_format(ad)
                for ad in ads
            ]
            records = [r for r in records if r is not None]  # –£–±–∏—Ä–∞–µ–º None

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            if records:
                import sqlite3
                with sqlite3.connect(self.db_handler.db_name) as conn:
                    cursor = conn.cursor()
                    cursor.executemany(
                        "INSERT OR REPLACE INTO viewed (id, price) VALUES (?, ?)",
                        records
                    )
                    conn.commit()
                logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(records)} –≤ –ë–î")
            else:
                logger.info("–ù–µ—á–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ –ë–î")

        except Exception as err:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {err}")

    def _convert_cian_to_db_format(self, ad: CianItem) -> tuple | None:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç CianItem –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –ë–î (id, price)"""
        try:
            if not ad.price or ad.price.value <= 0:
                return None

            ad_id = int(ad.id) if ad.id.isdigit() else abs(hash(ad.id))
            return (ad_id, ad.price.value)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è {ad.id}: {e}")
            return None

    def get_next_page_url(self, url: str) -> str:
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç URL —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            url_parts = urlparse(url)
            query_params = parse_qs(url_parts.query)
            current_page = int(query_params.get('p', [1])[0])
            query_params['p'] = [str(current_page + 1)]

            new_query = urlencode(query_params, doseq=True)
            next_url = urlunparse((
                url_parts.scheme, url_parts.netloc, url_parts.path,
                url_parts.params, new_query, url_parts.fragment
            ))
            return next_url
        except Exception as err:
            logger.error(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è URL: {err}")
            return url

    def parse(self):
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –¶–∏–∞–Ω –¥–ª—è –≥–æ—Ä–æ–¥–∞: {self.config.location}")

        for url_index, url in enumerate(self.config.urls):
            logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Å—ã–ª–∫–∏ {url_index + 1}/{len(self.config.urls)}")
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ region –≤ URL
            if 'region=' not in url:
                separator = '&' if '?' in url else '?'
                url = f"{url}{separator}region={self.city_code}"
                logger.info(f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω region={self.city_code} –≤ URL")
            else:
                import re
                url = re.sub(r'region=\d+', f'region={self.city_code}', url)
                logger.info(f"üîÑ –ó–∞–º–µ–Ω—ë–Ω region –Ω–∞ {self.city_code} –≤ URL")
            for page in range(self.config.count):
                if self.stop_event and self.stop_event.is_set():
                    return

                logger.info(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page + 1}/{self.config.count}")

                html = self.fetch_data(url=url, retries=self.config.max_count_of_retry)

                if not html:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å HTML –¥–ª—è {url}")
                    time.sleep(self.config.pause_between_links)
                    continue

                ads = self.parse_list_page(html)

                if not ads:
                    logger.info("–û–±—ä—è–≤–ª–µ–Ω–∏—è –∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å")
                    break

                filtered_ads = self.filter_ads(ads)

                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
                if self.tg_handler and not self.config.one_time_start:
                    for ad in filtered_ads:
                        self.tg_handler.send_to_tg(ad=ad)
                        pass

                if self.vk_handler and not self.config.one_time_start:
                    for ad in filtered_ads:
                        self.vk_handler.send_to_vk(ad=ad)
                        pass

                if filtered_ads:
                    logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é {len(filtered_ads)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
                    self.__save_viewed(ads=filtered_ads)
                    self.__save_data(ads=filtered_ads)

                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
                url = self.get_next_page_url(url)

                logger.info(f"–ü–∞—É–∑–∞ {self.config.pause_between_links} —Å–µ–∫.")
                time.sleep(self.config.pause_between_links)

        logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω. –•–æ—Ä–æ—à–∏–µ –∑–∞–ø—Ä–æ—Å—ã: {self.good_request_count}, –ø–ª–æ—Ö–∏–µ: {self.bad_request_count}")


if __name__ == "__main__":
    from load_config import load_cian_config

    try:
        config = load_cian_config()
    except Exception as err:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥–∞: {err}")
        exit(1)

    while True:
        try:
            parser = CianParser(config)
            parser.parse()

            if config.one_time_start:
                logger.info("–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω (one_time_start)")
                break

            logger.info(f"–ü–∞—É–∑–∞ {config.pause_general} —Å–µ–∫")
            time.sleep(config.pause_general)
        except Exception as err:
            logger.error(f"–û—à–∏–±–∫–∞: {err}. –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ 30 —Å–µ–∫")
            time.sleep(30)